{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10654083,"sourceType":"datasetVersion","datasetId":6597502}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"81cc0a9d-53e2-44e1-ba8f-64ce1dea02fa","cell_type":"code","source":"!pip install transformers torch datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:02.812777Z","iopub.execute_input":"2025-02-04T00:08:02.813108Z","iopub.status.idle":"2025-02-04T00:08:06.173563Z","shell.execute_reply.started":"2025-02-04T00:08:02.813071Z","shell.execute_reply":"2025-02-04T00:08:06.172721Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"id":"5bceaf99-87cc-4e9a-8fbc-043dd4285d2e","cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:06.176085Z","iopub.execute_input":"2025-02-04T00:08:06.176323Z","iopub.status.idle":"2025-02-04T00:08:13.811117Z","shell.execute_reply.started":"2025-02-04T00:08:06.176301Z","shell.execute_reply":"2025-02-04T00:08:13.810415Z"}},"outputs":[],"execution_count":3},{"id":"e50a2261-fd42-4d81-b354-27a8c96aeaff","cell_type":"code","source":"model_name = \"readerbench/RoBERT-base\"  # Romanian RoBERTa\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:13.812460Z","iopub.execute_input":"2025-02-04T00:08:13.812927Z","iopub.status.idle":"2025-02-04T00:08:30.837915Z","shell.execute_reply.started":"2025-02-04T00:08:13.812877Z","shell.execute_reply":"2025-02-04T00:08:30.836971Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4190ff32d44619befd6ac8a088f555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/468 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5a9a0a0ee34dc59319e088db280fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/245k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bdac780ccb749c89e56cfbb3ddf468a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75e75af63624bf6bb7143a4879bedad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/463M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3772251421a9459bbc485193bdac394d"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at readerbench/RoBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":4},{"id":"a0e791cd-7aa7-403a-bad7-dd462c5675e4","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:30.839250Z","iopub.execute_input":"2025-02-04T00:08:30.840810Z","iopub.status.idle":"2025-02-04T00:08:31.216291Z","shell.execute_reply.started":"2025-02-04T00:08:30.840780Z","shell.execute_reply":"2025-02-04T00:08:31.215499Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(37788, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":5},{"id":"fe500532-6cb4-4faa-934a-cc4054dc96d8","cell_type":"code","source":"def compute_metrics(model, tokenizer, text, verbose=False):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    logits = outputs.logits\n    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n    neg_log_likelihood = -torch.mean(torch.log(probabilities.max(dim=-1).values + 1e-9))\n\n    # Only print debugging info if verbose=True\n    if verbose:\n        print(f\"Text: {text[:50]}... | NLL: {neg_log_likelihood:.4f}\")\n\n    return neg_log_likelihood.item(), neg_log_likelihood.item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:38:41.207004Z","iopub.execute_input":"2025-02-04T00:38:41.207304Z","iopub.status.idle":"2025-02-04T00:38:41.212362Z","shell.execute_reply.started":"2025-02-04T00:38:41.207281Z","shell.execute_reply":"2025-02-04T00:38:41.211493Z"}},"outputs":[],"execution_count":17},{"id":"160a037e-db4b-483e-b173-1fc158e381a1","cell_type":"code","source":"import json\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:31.223340Z","iopub.execute_input":"2025-02-04T00:08:31.223569Z","iopub.status.idle":"2025-02-04T00:08:31.235931Z","shell.execute_reply.started":"2025-02-04T00:08:31.223550Z","shell.execute_reply":"2025-02-04T00:08:31.235151Z"}},"outputs":[],"execution_count":7},{"id":"acb84489-da4c-497c-b33c-dfee6eb12ccb","cell_type":"code","source":"regions = [\n    'Ardeal',\n    'Banat',\n    'Bucovina',\n    'Canada_EN',\n    'Canada_Quebec',\n    'Crisana',\n    'Dobrogea',\n    'Germania',\n    'Italia',\n    'Maramures',\n    'Moldova',\n    'Muntenia',\n    'Oltenia',\n    'Serbia',\n    'Spania',\n    'Ucraina',\n    'UK'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:31.236705Z","iopub.execute_input":"2025-02-04T00:08:31.236992Z","iopub.status.idle":"2025-02-04T00:08:31.251463Z","shell.execute_reply.started":"2025-02-04T00:08:31.236972Z","shell.execute_reply":"2025-02-04T00:08:31.250615Z"}},"outputs":[],"execution_count":8},{"id":"49f22abd-49d8-4cd0-b7dc-ab2ab45802f4","cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport numpy as np\n\nwith open(\"/kaggle/input/dataset-tari/dataset/Italia.json\") as f:\n    italia = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:08:31.252438Z","iopub.execute_input":"2025-02-04T00:08:31.252742Z","iopub.status.idle":"2025-02-04T00:08:31.271134Z","shell.execute_reply.started":"2025-02-04T00:08:31.252714Z","shell.execute_reply":"2025-02-04T00:08:31.270536Z"}},"outputs":[],"execution_count":9},{"id":"234b42a1-15ec-4712-b50d-bc5c0e1c6ddd","cell_type":"code","source":"import json\nimport numpy as np\nfrom tqdm import tqdm\n\nresults_regions = {}\n\nfor region in regions:\n    results_regions[region] = []\n    results_content = {\"perplexity\": [], \"neg_log_likelihood\": []}\n    results_titles = {\"perplexity\": [], \"neg_log_likelihood\": []}\n\n    with open(f\"/kaggle/input/dataset-tari/dataset/{region}.json\") as f:\n        region_json = json.load(f)\n\n    for row in tqdm(region_json, disable=True):  # Disable progress bar output\n        row_cnt_result = compute_metrics(model, tokenizer, row['content'] if 'content' in row else row['text'], verbose=False)\n        results_content['perplexity'].append(row_cnt_result[0])\n        results_content['neg_log_likelihood'].append(row_cnt_result[1])\n        \n        row_title_result = compute_metrics(model, tokenizer, row['title'], verbose=False)\n        results_titles['perplexity'].append(row_title_result[0])\n        results_titles['neg_log_likelihood'].append(row_title_result[1])\n\n    perp_content_mean = np.array(results_content['neg_log_likelihood']).mean()\n    perp_titles_mean = np.array(results_titles['neg_log_likelihood']).mean()\n\n    results_regions[region].append({\n        'content': results_content,\n        'titles': results_titles,\n        'perp_mean_content': perp_content_mean,\n        'perp_mean_titles': perp_titles_mean\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:38:44.960873Z","iopub.execute_input":"2025-02-04T00:38:44.961187Z","iopub.status.idle":"2025-02-04T00:48:35.215468Z","shell.execute_reply.started":"2025-02-04T00:38:44.961164Z","shell.execute_reply":"2025-02-04T00:48:35.214773Z"}},"outputs":[],"execution_count":18},{"id":"3896c743-375a-486c-8da9-0867b6a0072d","cell_type":"code","source":"import json\nimport numpy as np\n\n# Load results\nwith open(\"/kaggle/working/results_regions.json\", \"r\", encoding=\"utf-8\") as f:\n    results_regions = json.load(f)\n\n# Store all perplexities for overall statistics\nall_perplexities_content = []\nall_perplexities_titles = []\n\nprint(\"\\n📊 **Perplexity Statistics Per Region:**\")\nfor region, data in results_regions.items():\n    # Extract **all** perplexities, not just means\n    region_perplexities_content = [p for entry in data for p in entry[\"content\"][\"perplexity\"]]\n    region_perplexities_titles = [p for entry in data for p in entry[\"titles\"][\"perplexity\"]]\n\n    if not region_perplexities_content or not region_perplexities_titles:\n        print(f\"⚠️ No data available for {region}. Skipping...\")\n        continue  # Avoid crashing if a region has no perplexities\n\n    # Compute mean, min, and max correctly from all values\n    mean_content = np.mean(region_perplexities_content)\n    min_content = np.min(region_perplexities_content)\n    max_content = np.max(region_perplexities_content)\n\n    mean_titles = np.mean(region_perplexities_titles)\n    min_titles = np.min(region_perplexities_titles)\n    max_titles = np.max(region_perplexities_titles)\n\n    # Print per-region statistics\n    print(f\"📍 {region}:\")\n    print(f\"   - **Content**: Mean = {mean_content:.4f}, Min = {min_content:.4f}, Max = {max_content:.4f}\")\n    print(f\"   - **Titles**:  Mean = {mean_titles:.4f}, Min = {min_titles:.4f}, Max = {max_titles:.4f}\\n\")\n\n    # Collect for overall dataset statistics\n    all_perplexities_content.extend(region_perplexities_content)\n    all_perplexities_titles.extend(region_perplexities_titles)\n\n# Compute overall dataset statistics\nif all_perplexities_content and all_perplexities_titles:\n    dataset_mean_content = np.mean(all_perplexities_content)\n    dataset_min_content = np.min(all_perplexities_content)\n    dataset_max_content = np.max(all_perplexities_content)\n\n    dataset_mean_titles = np.mean(all_perplexities_titles)\n    dataset_min_titles = np.min(all_perplexities_titles)\n    dataset_max_titles = np.max(all_perplexities_titles)\n\n    # Print overall dataset statistics\n    print(\"\\n📊 **Overall Dataset Perplexity Statistics:**\")\n    print(f\"   - **Content**: Mean = {dataset_mean_content:.4f}, Min = {dataset_min_content:.4f}, Max = {dataset_max_content:.4f}\")\n    print(f\"   - **Titles**:  Mean = {dataset_mean_titles:.4f}, Min = {dataset_min_titles:.4f}, Max = {dataset_max_titles:.4f}\")\nelse:\n    print(\"⚠️ No perplexity data found in the dataset.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:09:37.400693Z","iopub.execute_input":"2025-02-04T01:09:37.401061Z","iopub.status.idle":"2025-02-04T01:09:37.476068Z","shell.execute_reply.started":"2025-02-04T01:09:37.401028Z","shell.execute_reply":"2025-02-04T01:09:37.475347Z"}},"outputs":[{"name":"stdout","text":"\n📊 **Perplexity Statistics Per Region:**\n📍 Ardeal:\n   - **Content**: Mean = 0.5664, Min = 0.3680, Max = 0.6930\n   - **Titles**:  Mean = 0.6265, Min = 0.4251, Max = 0.6931\n\n📍 Banat:\n   - **Content**: Mean = 0.5776, Min = 0.4119, Max = 0.6927\n   - **Titles**:  Mean = 0.6198, Min = 0.3661, Max = 0.6931\n\n📍 Bucovina:\n   - **Content**: Mean = 0.5715, Min = 0.3950, Max = 0.6930\n   - **Titles**:  Mean = 0.6249, Min = 0.4518, Max = 0.6927\n\n📍 Canada_EN:\n   - **Content**: Mean = 0.5977, Min = 0.4460, Max = 0.6918\n   - **Titles**:  Mean = 0.6523, Min = 0.5727, Max = 0.6930\n\n📍 Canada_Quebec:\n   - **Content**: Mean = 0.6069, Min = 0.4089, Max = 0.6912\n   - **Titles**:  Mean = 0.6568, Min = 0.5344, Max = 0.6928\n\n📍 Crisana:\n   - **Content**: Mean = 0.5996, Min = 0.3765, Max = 0.6928\n   - **Titles**:  Mean = 0.6298, Min = 0.4546, Max = 0.6927\n\n📍 Dobrogea:\n   - **Content**: Mean = 0.5785, Min = 0.3476, Max = 0.6928\n   - **Titles**:  Mean = 0.6153, Min = 0.4242, Max = 0.6927\n\n📍 Germania:\n   - **Content**: Mean = 0.5519, Min = 0.3874, Max = 0.6903\n   - **Titles**:  Mean = 0.6387, Min = 0.4751, Max = 0.6930\n\n📍 Italia:\n   - **Content**: Mean = 0.5771, Min = 0.4993, Max = 0.6687\n   - **Titles**:  Mean = 0.6429, Min = 0.5857, Max = 0.6895\n\n📍 Maramures:\n   - **Content**: Mean = 0.6196, Min = 0.3681, Max = 0.6904\n   - **Titles**:  Mean = 0.6258, Min = 0.4656, Max = 0.6928\n\n📍 Moldova:\n   - **Content**: Mean = 0.5729, Min = 0.3512, Max = 0.6930\n   - **Titles**:  Mean = 0.6250, Min = 0.3846, Max = 0.6931\n\n📍 Muntenia:\n   - **Content**: Mean = 0.5793, Min = 0.3579, Max = 0.6927\n   - **Titles**:  Mean = 0.6346, Min = 0.3579, Max = 0.6931\n\n📍 Oltenia:\n   - **Content**: Mean = 0.5830, Min = 0.3972, Max = 0.6931\n   - **Titles**:  Mean = 0.6299, Min = 0.3596, Max = 0.6931\n\n📍 Serbia:\n   - **Content**: Mean = 0.6096, Min = 0.4191, Max = 0.6931\n   - **Titles**:  Mean = 0.6398, Min = 0.4130, Max = 0.6931\n\n📍 Spania:\n   - **Content**: Mean = 0.5546, Min = 0.3954, Max = 0.6929\n   - **Titles**:  Mean = 0.6480, Min = 0.4371, Max = 0.6931\n\n📍 Ucraina:\n   - **Content**: Mean = 0.5748, Min = 0.3768, Max = 0.6930\n   - **Titles**:  Mean = 0.6571, Min = 0.5066, Max = 0.6931\n\n📍 UK:\n   - **Content**: Mean = 0.5798, Min = 0.3880, Max = 0.6928\n   - **Titles**:  Mean = 0.6311, Min = 0.5452, Max = 0.6927\n\n\n📊 **Overall Dataset Perplexity Statistics:**\n   - **Content**: Mean = 0.5789, Min = 0.3476, Max = 0.6931\n   - **Titles**:  Mean = 0.6327, Min = 0.3579, Max = 0.6931\n","output_type":"stream"}],"execution_count":27},{"id":"7e533ae7-0e81-4c3e-a40e-5a05e5b3c825","cell_type":"code","source":"import json\nimport numpy as np\n\n# Load results\nwith open(\"/kaggle/working/results_regions.json\", \"r\", encoding=\"utf-8\") as f:\n    results_regions = json.load(f)\n\n# Store all perplexities for overall dataset statistics\nall_perplexities_content = []\nall_perplexities_titles = []\n\nprint(\"\\n📊 **Perplexity Min & Max Per Region:**\")\nfor region, data in results_regions.items():\n    # Extract **all** perplexities, not just mean values\n    region_perplexities_content = [p for entry in data for p in entry[\"content\"][\"perplexity\"]]\n    region_perplexities_titles = [p for entry in data for p in entry[\"titles\"][\"perplexity\"]]\n\n    if not region_perplexities_content or not region_perplexities_titles:\n        print(f\"⚠️ No data available for {region}. Skipping...\")\n        continue  # Avoid crashing if a region has no perplexities\n\n    # Compute min & max correctly from all values\n    min_content = np.min(region_perplexities_content)\n    max_content = np.max(region_perplexities_content)\n    min_titles = np.min(region_perplexities_titles)\n    max_titles = np.max(region_perplexities_titles)\n\n    # Print per-region min & max\n    print(f\"📍 {region}:\")\n    print(f\"   - Min Perplexity (Content): {min_content:.4f}\")\n    print(f\"   - Max Perplexity (Content): {max_content:.4f}\")\n    print(f\"   - Min Perplexity (Titles): {min_titles:.4f}\")\n    print(f\"   - Max Perplexity (Titles): {max_titles:.4f}\\n\")\n\n    # Collect for overall dataset stats\n    all_perplexities_content.extend(region_perplexities_content)\n    all_perplexities_titles.extend(region_perplexities_titles)\n\n# Compute overall dataset min & max\nif all_perplexities_content and all_perplexities_titles:\n    dataset_min_content = np.min(all_perplexities_content)\n    dataset_max_content = np.max(all_perplexities_content)\n    dataset_min_titles = np.min(all_perplexities_titles)\n    dataset_max_titles = np.max(all_perplexities_titles)\n\n    # Print overall dataset min & max\n    print(\"\\n📊 **Overall Dataset Perplexity Min & Max:**\")\n    print(f\"   - Min Perplexity (Content): {dataset_min_content:.4f}\")\n    print(f\"   - Max Perplexity (Content): {dataset_max_content:.4f}\")\n    print(f\"   - Min Perplexity (Titles): {dataset_min_titles:.4f}\")\n    print(f\"   - Max Perplexity (Titles): {dataset_max_titles:.4f}\")\nelse:\n    print(\"⚠️ No perplexity data found in the dataset.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:06:44.279181Z","iopub.execute_input":"2025-02-04T01:06:44.279507Z","iopub.status.idle":"2025-02-04T01:06:44.352796Z","shell.execute_reply.started":"2025-02-04T01:06:44.279481Z","shell.execute_reply":"2025-02-04T01:06:44.352123Z"}},"outputs":[{"name":"stdout","text":"\n📊 **Perplexity Min & Max Per Region:**\n📍 Ardeal:\n   - Min Perplexity (Content): 0.3680\n   - Max Perplexity (Content): 0.6930\n   - Min Perplexity (Titles): 0.4251\n   - Max Perplexity (Titles): 0.6931\n\n📍 Banat:\n   - Min Perplexity (Content): 0.4119\n   - Max Perplexity (Content): 0.6927\n   - Min Perplexity (Titles): 0.3661\n   - Max Perplexity (Titles): 0.6931\n\n📍 Bucovina:\n   - Min Perplexity (Content): 0.3950\n   - Max Perplexity (Content): 0.6930\n   - Min Perplexity (Titles): 0.4518\n   - Max Perplexity (Titles): 0.6927\n\n📍 Canada_EN:\n   - Min Perplexity (Content): 0.4460\n   - Max Perplexity (Content): 0.6918\n   - Min Perplexity (Titles): 0.5727\n   - Max Perplexity (Titles): 0.6930\n\n📍 Canada_Quebec:\n   - Min Perplexity (Content): 0.4089\n   - Max Perplexity (Content): 0.6912\n   - Min Perplexity (Titles): 0.5344\n   - Max Perplexity (Titles): 0.6928\n\n📍 Crisana:\n   - Min Perplexity (Content): 0.3765\n   - Max Perplexity (Content): 0.6928\n   - Min Perplexity (Titles): 0.4546\n   - Max Perplexity (Titles): 0.6927\n\n📍 Dobrogea:\n   - Min Perplexity (Content): 0.3476\n   - Max Perplexity (Content): 0.6928\n   - Min Perplexity (Titles): 0.4242\n   - Max Perplexity (Titles): 0.6927\n\n📍 Germania:\n   - Min Perplexity (Content): 0.3874\n   - Max Perplexity (Content): 0.6903\n   - Min Perplexity (Titles): 0.4751\n   - Max Perplexity (Titles): 0.6930\n\n📍 Italia:\n   - Min Perplexity (Content): 0.4993\n   - Max Perplexity (Content): 0.6687\n   - Min Perplexity (Titles): 0.5857\n   - Max Perplexity (Titles): 0.6895\n\n📍 Maramures:\n   - Min Perplexity (Content): 0.3681\n   - Max Perplexity (Content): 0.6904\n   - Min Perplexity (Titles): 0.4656\n   - Max Perplexity (Titles): 0.6928\n\n📍 Moldova:\n   - Min Perplexity (Content): 0.3512\n   - Max Perplexity (Content): 0.6930\n   - Min Perplexity (Titles): 0.3846\n   - Max Perplexity (Titles): 0.6931\n\n📍 Muntenia:\n   - Min Perplexity (Content): 0.3579\n   - Max Perplexity (Content): 0.6927\n   - Min Perplexity (Titles): 0.3579\n   - Max Perplexity (Titles): 0.6931\n\n📍 Oltenia:\n   - Min Perplexity (Content): 0.3972\n   - Max Perplexity (Content): 0.6931\n   - Min Perplexity (Titles): 0.3596\n   - Max Perplexity (Titles): 0.6931\n\n📍 Serbia:\n   - Min Perplexity (Content): 0.4191\n   - Max Perplexity (Content): 0.6931\n   - Min Perplexity (Titles): 0.4130\n   - Max Perplexity (Titles): 0.6931\n\n📍 Spania:\n   - Min Perplexity (Content): 0.3954\n   - Max Perplexity (Content): 0.6929\n   - Min Perplexity (Titles): 0.4371\n   - Max Perplexity (Titles): 0.6931\n\n📍 Ucraina:\n   - Min Perplexity (Content): 0.3768\n   - Max Perplexity (Content): 0.6930\n   - Min Perplexity (Titles): 0.5066\n   - Max Perplexity (Titles): 0.6931\n\n📍 UK:\n   - Min Perplexity (Content): 0.3880\n   - Max Perplexity (Content): 0.6928\n   - Min Perplexity (Titles): 0.5452\n   - Max Perplexity (Titles): 0.6927\n\n\n📊 **Overall Dataset Perplexity Min & Max:**\n   - Min Perplexity (Content): 0.3476\n   - Max Perplexity (Content): 0.6931\n   - Min Perplexity (Titles): 0.3579\n   - Max Perplexity (Titles): 0.6931\n","output_type":"stream"}],"execution_count":26}]}